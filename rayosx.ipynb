{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNeRUad4suaiM+oiD7TyQ1t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MurtDev/Alura-Geek/blob/main/rayosx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JbV5UKOnwALy",
        "outputId": "8902f9fb-10fc-49ea-987e-6e338f72aa52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.4.14-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.13.0.92)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cpu)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (26.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2026.1.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.4.14-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.4.14 ultralytics-thop-2.0.18\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ultralytics\n",
        "print(ultralytics.__version__)\n",
        "\n",
        "import ultralytics\n",
        "print(ultralytics.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2HbJWF0ww_W",
        "outputId": "b5d721d9-27be-4f87-f94c-b10bbb7184de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "8.4.14\n",
            "8.4.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Crea una variable para la ruta base de tu proyecto en Drive\n",
        "drive_path = '/content/drive/MyDrive/YOLO_Fracturas/'\n",
        "\n",
        "# (Opcional) Crea la carpeta si no existe\n",
        "!mkdir -p {drive_path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Nf1TB7ew4D6",
        "outputId": "14e27bdd-c099-4321-ff15-c5e1d337a27e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = drive_path + 'archive.zip'\n",
        "# Use -o flag to overwrite existing files without prompting\n",
        "!unzip -o -q {zip_path} -d /content/data/\n",
        "dataset_path = '/content/data/archive/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meyvde-rzo0w",
        "outputId": "45841f8c-a26d-4979-f8f3-c672235ab76e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/drive/MyDrive/YOLO_Fracturas/archive.zip, /content/drive/MyDrive/YOLO_Fracturas/archive.zip.zip or /content/drive/MyDrive/YOLO_Fracturas/archive.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('/content/data/archive/BoneBreakClassification/data.yaml')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GObjHSVR5kg7",
        "outputId": "92039966-d1a7-4947-cfe9-d48d66312e8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data/archive/BoneBreakClassification/data.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow keras numpy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBq3r2LV8UrS",
        "outputId": "99a62297-e701-42a0-e85d-9d22618a048f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.12.19)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (26.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.1.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras) (0.18.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.46.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2026.1.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "# --- 1. Definir Rutas ---\n",
        "# The data was unzipped to /content/data/. Based on the previous unzip output,\n",
        "# the actual dataset root seems to be nested within '/content/data/'.\n",
        "# Let's adjust this path to where the 'train' and 'valid' folders actually reside.\n",
        "# Assuming the unzipped structure is /content/data/Bone Break Classification/Bone Break Classification/\n",
        "BASE_DIR_ENTRENAMIENTO = '/content/data/Bone Break Classification/Bone Break Classification/'\n",
        "\n",
        "# --- 2. Preparar el Generador de Datos ---\n",
        "# Solo rescalamos (normalizamos) para la validaci√≥n y prueba.\n",
        "# Si quieres hacer Aumento de Datos, a√±√°delo en train_datagen.\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=15, zoom_range=0.1)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# --- 3. Crear los Generadores ---\n",
        "\n",
        "# Definimos las rutas a las subcarpetas 'train' y 'valid'\n",
        "train_path = os.path.join(BASE_DIR_ENTRENAMIENTO, 'train') # Asume que tienes un 'train' en la ra√≠z\n",
        "val_path = os.path.join(BASE_DIR_ENTRENAMIENTO, 'valid') # Asume que tienes un 'valid' en la ra√≠z\n",
        "\n",
        "# OJO: Si las carpetas 'train'/'valid' est√°n DENTRO de cada tipo de fractura,\n",
        "# necesitaremos un script para mover las im√°genes a una sola carpeta de 'train' y 'valid'.\n",
        "\n",
        "# Asumiendo una estructura consolidada:\n",
        "# BASE_DIR/\n",
        "# ‚îú‚îÄ‚îÄ train/\n",
        "# ‚îÇ   ‚îú‚îÄ‚îÄ avulsion fracture/ (im√°genes aqu√≠)\n",
        "# ‚îÇ   ‚îú‚îÄ‚îÄ comminuted fracture/ (im√°genes aqu√≠)\n",
        "# ...\n",
        "\n",
        "# Si la estructura est√° consolidada:\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical' # <-- CAMBIO CLAVE: Usa 'categorical' para multiclase\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# El generador te dir√° cu√°ntas clases ha encontrado:\n",
        "NUM_CLASES = train_generator.num_classes\n",
        "print(f\"El generador encontr√≥ {NUM_CLASES} clases: {train_generator.class_indices}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "collapsed": true,
        "id": "H4Wlr7VF8x0N",
        "outputId": "e83f904d-ab12-4c07-82fc-d99ab2a0fe17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/data/Bone Break Classification/Bone Break Classification/train'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2794066272.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Si la estructura est√° consolidada:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m train_generator = train_datagen.flow_from_directory(\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0mkeep_aspect_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m     ):\n\u001b[0;32m-> 1138\u001b[0;31m         return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1139\u001b[0m             \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/legacy/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data/Bone Break Classification/Bone Break Classification/train'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow keras numpy\n"
      ],
      "metadata": {
        "id": "Ku6ezJ8w-EZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define la ruta base donde est√° tu dataset en Drive\n",
        "DRIVE_BASE_PATH = '/content/drive/MyDrive/YOLO_Fracturas/archive/bone break classification/'\n",
        "\n",
        "# Crea la ruta LOCAL de Colab para consolidar los datos\n",
        "CONSOLIDATED_PATH = '/content/consolidated_data/'\n",
        "!mkdir -p {CONSOLIDATED_PATH}train\n",
        "!mkdir -p {CONSOLIDATED_PATH}valid"
      ],
      "metadata": {
        "id": "SGrBMmym-Hdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Lista de todos los tipos de fractura (nombres de las carpetas)\n",
        "fracture_types = [name for name in os.listdir(DRIVE_BASE_PATH) if os.path.isdir(os.path.join(DRIVE_BASE_PATH, name))]\n",
        "\n",
        "NUM_CLASES = len(fracture_types)\n",
        "print(f\"Clases detectadas: {NUM_CLASES}\")\n",
        "print(f\"Nombres de las clases: {fracture_types}\")\n",
        "\n",
        "if NUM_CLASES == 0:\n",
        "    print(\"üö® ERROR: No se encontraron subcarpetas (tipos de fractura) en la ruta. Revisa DRIVE_BASE_PATH.\")"
      ],
      "metadata": {
        "id": "ITmlt4Js-LNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -F '/content/drive/MyDrive/'\n"
      ],
      "metadata": {
        "id": "D4094OnK-tiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -F '/content/drive/MyDrive/YOLO_Fracturas/'"
      ],
      "metadata": {
        "id": "1uj8DyVw-xlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -F '/content/drive/MyDrive/YOLO_Fracturas/archive/'"
      ],
      "metadata": {
        "id": "PLZOL6cZ-zyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -F '/content/drive/MyDrive/YOLO_Fracturas/archive/Bone Break Classification/'"
      ],
      "metadata": {
        "id": "CusvU3NO-2rK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -F '/content/drive/MyDrive/YOLO_Fracturas/archive/Bone Break Classification/Avulsion fracture/'\n"
      ],
      "metadata": {
        "id": "Puq8b7A2_A6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# --- CORRECCI√ìN DE LA RUTA BASE ---\n",
        "# La ruta base debe ser donde est√°n las 7 subcarpetas de tipos de fractura.\n",
        "# NOTA: En Python, manejamos los espacios sin necesidad de comillas, solo con la escritura exacta.\n",
        "# Asumiendo que esta es la ruta correcta:\n",
        "DRIVE_BASE_PATH = '/content/drive/MyDrive/YOLO_Fracturas/archive/Bone Break Classification/'\n",
        "\n",
        "# Crea la ruta LOCAL de Colab para consolidar los datos (igual que antes)\n",
        "CONSOLIDATED_PATH = '/content/consolidated_data/'\n",
        "!mkdir -p {CONSOLIDATED_PATH}train\n",
        "!mkdir -p {CONSOLIDATED_PATH}valid\n",
        "\n",
        "print(f\"Nueva ruta base definida: {DRIVE_BASE_PATH}\")"
      ],
      "metadata": {
        "id": "Cr6pka-t_RHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Detecci√≥n de Clases ---\n",
        "\n",
        "# Esta vez s√≠ encontrar√° las subcarpetas de tipos de fractura\n",
        "fracture_types = [name for name in os.listdir(DRIVE_BASE_PATH) if os.path.isdir(os.path.join(DRIVE_BASE_PATH, name))]\n",
        "\n",
        "NUM_CLASES = len(fracture_types)\n",
        "print(f\"\\n‚úÖ Clases detectadas ({NUM_CLASES}): {fracture_types}\")\n",
        "\n",
        "# --- 2. Consolidaci√≥n y Reorganizaci√≥n de Archivos ---\n",
        "\n",
        "# Usaremos 'Test' y 'Train' seg√∫n la estructura que nos mostraste.\n",
        "# En Keras, 'Test' y 'Valid' se usan indistintamente para evaluaci√≥n.\n",
        "# Usaremos Train y Test.\n",
        "\n",
        "for class_name in fracture_types:\n",
        "    print(f\"Procesando: {class_name}\")\n",
        "\n",
        "    # Rutas de Origen (Drive) - Usando 'Train' y 'Test'\n",
        "    source_train = os.path.join(DRIVE_BASE_PATH, class_name, 'Train')\n",
        "    source_test = os.path.join(DRIVE_BASE_PATH, class_name, 'Test') # Usamos Test como validaci√≥n\n",
        "\n",
        "    # Rutas de Destino (Colab Local) - Nombres correctos para Keras\n",
        "    dest_train = os.path.join(CONSOLIDATED_PATH, 'train', class_name)\n",
        "    dest_test = os.path.join(CONSOLIDATED_PATH, 'valid', class_name) # Usamos 'valid' como carpeta de destino\n",
        "\n",
        "    # Crear directorios de destino\n",
        "    !mkdir -p \"{dest_train}\"\n",
        "    !mkdir -p \"{dest_test}\"\n",
        "\n",
        "    # Mover im√°genes de Train\n",
        "    # El 'mv' puede fallar si la ruta es muy larga o tiene caracteres especiales,\n",
        "    # pero para archivos de Drive suele funcionar bien.\n",
        "    print(f\"  Moviendo Train desde {source_train}...\")\n",
        "    !mv -t \"{dest_train}\" \"{source_train}\"/*\n",
        "\n",
        "    # Mover im√°genes de Test (las usaremos como validaci√≥n)\n",
        "    print(f\"  Moviendo Test (a valid) desde {source_test}...\")\n",
        "    !mv -t \"{dest_test}\" \"{source_test}\"/*\n",
        "\n",
        "print(\"\\n‚úÖ ¬°Consolidaci√≥n de datos completada!\")\n",
        "print(f\"La carpeta '{CONSOLIDATED_PATH}train' ahora tiene subcarpetas para cada clase.\")"
      ],
      "metadata": {
        "id": "1Vyahefk_U-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "# Rutas que apuntan a la carpeta consolidada\n",
        "CONSOLIDATED_PATH = '/content/consolidated_data/'\n",
        "train_path = os.path.join(CONSOLIDATED_PATH, 'train')\n",
        "val_path = os.path.join(CONSOLIDATED_PATH, 'valid')\n",
        "\n",
        "# 1. Definici√≥n del Generador\n",
        "# train_datagen incluye normalizaci√≥n (1./255) y Aumento de Datos (rotaci√≥n, zoom)\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=15,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True # Aumento de datos para mejorar el entrenamiento\n",
        ")\n",
        "# val_datagen solo normaliza\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# 2. Creaci√≥n de Generadores de Datos (usando la ruta consolidada)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(224, 224), # Todas las im√°genes se redimensionan a 224x224\n",
        "    batch_size=32,\n",
        "    class_mode='categorical' # Necesario para clasificaci√≥n multiclase\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Keras ya ha detectado las clases y sus √≠ndices\n",
        "class_names = list(train_generator.class_indices.keys())\n",
        "NUM_CLASES = len(class_names)\n",
        "\n",
        "print(f\"\\nEl generador Keras encontr√≥ {NUM_CLASES} clases: {class_names}\")\n",
        "print(\"‚úÖ Generadores de datos listos para el entrenamiento.\")"
      ],
      "metadata": {
        "id": "4_fSB60HAYO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import os\n",
        "\n",
        "# Define la ruta de tu Drive para guardar el modelo\n",
        "DRIVE_BASE_PATH = '/content/drive/MyDrive/YOLO_Fracturas/archive/Bone Break Classification/'\n",
        "\n",
        "# --- 1. Modelo Base (Transfer Learning) ---\n",
        "# Descarga el modelo base DenseNet121 preentrenado en ImageNet\n",
        "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Congelar capas base para que solo se entrenen las nuevas capas de clasificaci√≥n\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# --- 2. Capas de Clasificaci√≥n Personalizadas ---\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "# Capa de salida con activaci√≥n 'softmax' para multiclase\n",
        "predictions = Dense(NUM_CLASES, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# --- 3. Compilaci√≥n y Entrenamiento ---\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='categorical_crossentropy', # P√©rdida para m√°s de dos clases\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Callbacks para guardar el mejor modelo en tu Drive\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=os.path.join(DRIVE_BASE_PATH, 'mejor_modelo_fracturas_densenet.h5'),\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True,\n",
        "    mode='max',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Iniciar el entrenamiento (Esto tomar√° tiempo, revisa las m√©tricas)\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    epochs=20, # N√∫mero de ciclos de entrenamiento (puedes aumentarlo si la precisi√≥n sigue subiendo)\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[checkpoint]\n",
        ")\n",
        "\n",
        "print(\"\\n‚úÖ Entrenamiento completado. El mejor modelo se ha guardado en tu Drive.\")"
      ],
      "metadata": {
        "id": "Bn8Ukkc9AbbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gRPK4d2cX9Hd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# --- RUTAS CLAVE ---\n",
        "# 1. Cargar el mejor modelo\n",
        "DRIVE_BASE_PATH = '/content/drive/MyDrive/YOLO_Fracturas/archive/Bone Break Classification/'\n",
        "MODEL_PATH = os.path.join(DRIVE_BASE_PATH, 'mejor_modelo_fracturas_densenet.h5')\n",
        "model = load_model(MODEL_PATH)\n",
        "print(f\"Modelo cargado desde: {MODEL_PATH}\")\n",
        "\n",
        "# 2. üö® RUTA DE LA CARPETA DE IM√ÅGENES NUEVAS üö®\n",
        "# ¬°AJUSTA ESTA RUTA A DONDE SUBISTE TUS ARCHIVOS!\n",
        "IMG_FOLDER_PATH = '/content/drive/MyDrive/Radiografias_A_Diagnosticar/'\n",
        "\n",
        "# Recuperamos los nombres de clase que Keras mape√≥ en el generador del Paso 4\n",
        "# Aseg√∫rate de que la variable 'class_names' del Paso 4 siga disponible en tu entorno.\n",
        "# class_names = ['avulsion fracture', 'comminuted fracture', ...]\n",
        "\n",
        "print(\"\\n--- INICIANDO DIAGN√ìSTICO MASIVO ---\")\n",
        "\n",
        "# --- ITERAR SOBRE TODOS LOS ARCHIVOS EN LA CARPETA ---\n",
        "for filename in os.listdir(IMG_FOLDER_PATH):\n",
        "    # Asegurarse de que solo se procesan archivos de imagen\n",
        "    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "\n",
        "        full_img_path = os.path.join(IMG_FOLDER_PATH, filename)\n",
        "\n",
        "        try:\n",
        "            # 3. Pre-procesar la imagen\n",
        "            img = image.load_img(full_img_path, target_size=(224, 224))\n",
        "            img_array = image.img_to_array(img)\n",
        "            img_array = np.expand_dims(img_array / 255.0, axis=0)\n",
        "\n",
        "            # 4. Hacer la predicci√≥n\n",
        "            probabilities = model.predict(img_array)[0]\n",
        "            predicted_index = np.argmax(probabilities)\n",
        "            confidence = probabilities[predicted_index] * 100\n",
        "\n",
        "            # 5. Interpretar el resultado\n",
        "            predicted_class_name = class_names[predicted_index] # Obtener el nombre de la clase\n",
        "\n",
        "            # --- IMPRIMIR RESULTADOS ---\n",
        "            print(f\"\\n--- Analizando: {filename} ---\")\n",
        "            print(f\"Predicci√≥n: Tipo de Fractura - **{predicted_class_name.upper()}**\")\n",
        "            print(f\"Confianza: **{confidence:.2f}%**\")\n",
        "            #\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nüö® Error al procesar {filename}: {e}\")\n",
        "\n",
        "print(\"\\n--- DIAGN√ìSTICO MASIVO FINALIZADO ---\")"
      ],
      "metadata": {
        "id": "JdVbthVpN5Hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# --- RUTAS CLAVE ---\n",
        "DRIVE_BASE_PATH = '/content/drive/MyDrive/YOLO_Fracturas/archive/Bone Break Classification/'\n",
        "IMG_FOLDER_PATH = '/content/drive/MyDrive/Radiografias_A_Diagnosticar/'\n",
        "class_names = ['Avulsion fracture', 'Comminuted fracture', 'Fracture Dislocation', 'Greenstick fracture', 'Hairline Fracture', 'Impacted fracture', 'Longitudinal fracture', 'Oblique fracture', 'Pathological fracture', 'Spiral Fracture']\n",
        "\n",
        "# Cargar el modelo\n",
        "MODEL_PATH = os.path.join(DRIVE_BASE_PATH, 'mejor_modelo_fracturas_densenet.h5')\n",
        "\n",
        "# Verificar si el archivo del modelo existe antes de cargarlo\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    print(f\"\\nüö® ERROR: El archivo del modelo no se encontr√≥ en: {MODEL_PATH}\")\n",
        "    print(\"Por favor, aseg√∫rate de haber ejecutado el Paso 5 (entrenamiento del modelo) y que el modelo se haya guardado correctamente en tu Google Drive.\")\n",
        "    # Puedes a√±adir un exit() o sys.exit() aqu√≠ si quieres detener la ejecuci√≥n\n",
        "else:\n",
        "    model = load_model(MODEL_PATH)\n",
        "    print(f\"Modelo cargado desde: {MODEL_PATH}\")\n",
        "\n",
        "    print(\"\\n--- INICIANDO DIAGN√ìSTICO DETALLADO ---\")\n",
        "\n",
        "    # --- ITERAR SOBRE TODOS LOS ARCHIVOS EN LA CARPETA ---\n",
        "    for filename in os.listdir(IMG_FOLDER_PATH):\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            full_img_path = os.path.join(IMG_FOLDER_PATH, filename)\n",
        "\n",
        "            try:\n",
        "                # Pre-procesar la imagen\n",
        "                img = image.load_img(full_img_path, target_size=(224, 224))\n",
        "                img_array = image.img_to_array(img)\n",
        "                img_array = np.expand_dims(img_array / 255.0, axis=0)\n",
        "\n",
        "                # Hacer la predicci√≥n\n",
        "                probabilities = model.predict(img_array)[0]\n",
        "                predicted_index = np.argmax(probabilities)\n",
        "                confidence = probabilities[predicted_index] * 100\n",
        "                predicted_class_name = class_names[predicted_index]\n",
        "\n",
        "                # --- Generar Reporte Detallado ---\n",
        "                print(f\"\\n--- üìã REPORTE DE IMAGEN: {filename} ---\")\n",
        "\n",
        "                # Clasificaci√≥n principal\n",
        "                print(f\"**DIAGN√ìSTICO PRINCIPAL:** {predicted_class_name.upper()}\")\n",
        "                print(f\"**Nivel de Confianza (IA):** {confidence:.2f}%\")\n",
        "\n",
        "                # Advertencia de baja confianza\n",
        "                if confidence < 70:\n",
        "                    print(\"‚ö†Ô∏è ADVERTENCIA: La confianza es BAJA. Se recomienda la revisi√≥n humana.\")\n",
        "\n",
        "                # Mostrar las top 3 probabilidades\n",
        "                top_indices = np.argsort(probabilities)[::-1][:3] # Obtener los 3 √≠ndices m√°s altos\n",
        "                print(\"\\n**TOP 3 PROBABILIDADES:**\")\n",
        "                for rank, idx in enumerate(top_indices):\n",
        "                    class_name_es = class_names[idx].replace(\" fracture\", \" fractura\").replace(\"Avulsion\", \"Avulsi√≥n\").replace(\"Comminuted\", \"Conminuta\").replace(\"Pathological\", \"Patol√≥gica\")\n",
        "                    print(f\"  {rank+1}. {class_name_es} ({(probabilities[idx]*100):.2f}%)\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"\\nüö® Error al procesar {filename}: {e}\")\n",
        "\n",
        "    print(\"\\n--- DIAGN√ìSTICO MASIVO FINALIZADO ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zw4R-s0HPWLY",
        "outputId": "e03555a3-ca9b-439d-a448-2af590b8fc45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado desde: /content/drive/MyDrive/YOLO_Fracturas/archive/Bone Break Classification/mejor_modelo_fracturas_densenet.h5\n",
            "\n",
            "--- INICIANDO DIAGN√ìSTICO DETALLADO ---\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "\n",
            "--- üìã REPORTE DE IMAGEN: radiografia-de-torax-frontal-valencia-1024x839.jpg ---\n",
            "**DIAGN√ìSTICO PRINCIPAL:** PATHOLOGICAL FRACTURE\n",
            "**Nivel de Confianza (IA):** 37.10%\n",
            "‚ö†Ô∏è ADVERTENCIA: La confianza es BAJA. Se recomienda la revisi√≥n humana.\n",
            "\n",
            "**TOP 3 PROBABILIDADES:**\n",
            "  1. Patol√≥gica fractura (37.10%)\n",
            "  2. Impacted fractura (19.14%)\n",
            "  3. Hairline Fracture (12.56%)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step\n",
            "\n",
            "--- üìã REPORTE DE IMAGEN: Collesfracture.jpg ---\n",
            "**DIAGN√ìSTICO PRINCIPAL:** PATHOLOGICAL FRACTURE\n",
            "**Nivel de Confianza (IA):** 62.37%\n",
            "‚ö†Ô∏è ADVERTENCIA: La confianza es BAJA. Se recomienda la revisi√≥n humana.\n",
            "\n",
            "**TOP 3 PROBABILIDADES:**\n",
            "  1. Patol√≥gica fractura (62.37%)\n",
            "  2. Spiral Fracture (10.29%)\n",
            "  3. Conminuta fractura (7.38%)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step\n",
            "\n",
            "--- üìã REPORTE DE IMAGEN: 493005523_1084691477024641_2020547562723528927_n.jpg ---\n",
            "**DIAGN√ìSTICO PRINCIPAL:** PATHOLOGICAL FRACTURE\n",
            "**Nivel de Confianza (IA):** 46.44%\n",
            "‚ö†Ô∏è ADVERTENCIA: La confianza es BAJA. Se recomienda la revisi√≥n humana.\n",
            "\n",
            "**TOP 3 PROBABILIDADES:**\n",
            "  1. Patol√≥gica fractura (46.44%)\n",
            "  2. Impacted fractura (18.96%)\n",
            "  3. Spiral Fracture (10.88%)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step\n",
            "\n",
            "--- üìã REPORTE DE IMAGEN: Nueva-imagen-1.png ---\n",
            "**DIAGN√ìSTICO PRINCIPAL:** SPIRAL FRACTURE\n",
            "**Nivel de Confianza (IA):** 40.67%\n",
            "‚ö†Ô∏è ADVERTENCIA: La confianza es BAJA. Se recomienda la revisi√≥n humana.\n",
            "\n",
            "**TOP 3 PROBABILIDADES:**\n",
            "  1. Spiral Fracture (40.67%)\n",
            "  2. Oblique fractura (13.66%)\n",
            "  3. Fracture Dislocation (11.03%)\n",
            "\n",
            "--- DIAGN√ìSTICO MASIVO FINALIZADO ---\n"
          ]
        }
      ]
    }
  ]
}